#!/usr/bin/env python3

import requests
import argparse
import os
from datetime import datetime

# List of important security headers
SECURITY_HEADERS = [
    "Content-Security-Policy",
    "Strict-Transport-Security",
    "X-Frame-Options",
    "X-Content-Type-Options",
    "Referrer-Policy",
    "Permissions-Policy"
]

def check_headers(url):
    try:
        response = requests.get(url, timeout=10)
        headers = response.headers

        print(f"\n[+] Checking headers for: {url}")
        missing = []

        for header in SECURITY_HEADERS:
            if header in headers:
                print(f"✔ {header}: {headers[header]}")
            else:
                print(f"✘ {header} is missing")
                missing.append(header)

        # Save log
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        filename = f"logs/{url.replace('https://', '').replace('http://', '').replace('/', '_')}_{timestamp}.log"
        with open(filename, "w") as f:
            f.write(f"Scanned URL: {url}\n\n")
            for header in SECURITY_HEADERS:
                if header in headers:
                    f.write(f"{header}: {headers[header]}\n")
                else:
                    f.write(f"{header}: MISSING\n")
        print(f"\n[+] Report saved: {filename}")

    except Exception as e:
        print(f"[!] Error fetching headers: {e}")

def main():
    parser = argparse.ArgumentParser(description="auto-headers: Scan for missing HTTP security headers")
    parser.add_argument("-u", "--url", required=True, help="Target URL (include http/https)")
    args = parser.parse_args()

    check_headers(args.url)

if __name__ == "__main__":
    main()
